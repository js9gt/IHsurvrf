



set.seed(123)
source("R/IH.VerifyModels.R")
source("R/class_IH.Parameters.R")
source("R/IH.survRF.R")
source("R/IH.predictSurvTree.R")
source("R/IH.VerifySampleSize.R")
source("R/class_IH.DTRSurvStep.R")


library(survival)
library(IHsurvrf)

dyn.load("src/IHsurvrf.so")



## simulate data for 3 stages
dt <- data.frame("Y.1" = sample(1:100,100,TRUE), "Y.2" = sample(1:100,100,TRUE), "Y.3" = sample(1:100,100,TRUE),
                 "D.1" = rbinom(100, 1, 0.9), "D.2" = rbinom(100,1,0.9), "D.3" = rbinom(100,1,0.9),
                 "A.1" = rbinom(100, 1, 0.5), "A.2" = rbinom(100,1,0.5), "A.3" = rbinom(100,1,0.5),
                 "X.1" = rnorm(100), "X.2" = rnorm(100),"X.3" = rnorm(100))
#
#
#
## defined in VerifyTxName.R Script
# txName = A.1 (binary treatment 0 or 1)
# character
#
txName <- c("A.1", "A.2", "A.3")
#
#
## create model
###### NOTE: use Verifymodels.R
models <-Surv(Y,D)~X+A
#
#
nDP <- 3
#
## defined in VerifyUsePrevTime.R script
#
usePrevTime <- T
#
stageLabel <- "."

sampleSize = NULL
mTry = 10L
#
# ensure that 'models' is provided as a formula or a list of formula and
# that the provided models can be generated by the data. If the input is
# appropriate, the object returned is list containing
#   "models" - the original input.
#   "response" - matrix of the survival response variables
#
## used in script VerifyModels.R
#
models <- .VerifyModels(models = models,
                        nDP = nDP,
                        data = dt,
                        txName = txName,
                        stageLabel = stageLabel,
                        usePrevTime = usePrevTime)
#
#
## extracts the "response variable": matrix of survival response variables
response <- models$response
#
## extracts the "delta" variable
del <- models$delta
#
## only including the models themselves & discarding "response" and "delta" components
models <- models$models


# convert to list for single decision analyses for convenience
if (!is.list(x = models)) models <- list(models)
#
## create params
#
params <- .parameters(timePoints = "exp",
                      tau = NULL,
                      nTimes = 10L,
                      response = response,
                      nTree = 10L,
                      ERT = TRUE,
                      uniformSplit = NULL,
                      randomSplit = 0.2,
                      splitRule = NULL,
                      replace = NULL,
                      nodeSize = 6L,
                      minEvent = 2L,
                      tieMethod = "random",
                      criticalValue = "surv.prob",
                      survivalTime = NULL,
                      nSamples = nSamples,
                      pooled = TRUE,
                      stratifiedSplit = NULL)

.CriticalValueCriterion(params)

crit <- .CriticalValueCriterion(params)
if (crit == "mean") {

  ## set index to 0 (integer)
  ind = 0L

  ## set fraction to 0.0
  frac = 0.0

  ## meaning, for mean-based criteria, specific index and fraction aren't applicable or needed

} else if (crit == "surv.mean" || crit == "surv.prob") {

  ## retrieve the "Index" and the"sFraction" from the params object
  ## these are output depending on the input "survivalTime" parameter
  ind = params@sIndex
  frac = params@sFraction
}

# set basic parameter values in Fortran
## call a Fortran subroutine named "setUpBasics"
## in dtrSurv.f90 code

res = .Fortran("setUpBasics",

               ## retrieve the number of timepoints
               t_nt = as.integer(x = .NTimes(object = params)),

               ## retrieve the difference in timepoints
               t_dt = as.double(x = .TimeDiff(object = params)),

               ## retrieves the "randomSplit" (input) parameter as a double
               ## this is then fed into fortran as the probability of random split (rs)
               t_rs = as.double(x = params@randomSplit),

               ## retrieves logical of whether extremeley randomized trees *ERT* are used (as integer)
               t_ERT = as.integer(x = params@ERT),

               ## retrieves logical of whether uniform splits are used (as integer)
               t_uniformSplit = as.integer(x = params@uniformSplit),

               ## min number of samples required at a tree node to consider a split (as integer)
               ## defined in class_IH.TreeConditions
               t_nodeSize = as.integer(x = .NodeSize(object = params)),

               ## min number of events present in node (as integer)
               ## defined in class_TreeConditions.R
               ## return the minEvent slot (integer): minimum number of events allowed in a node

               t_minEvent = as.integer(x = .MinEvent(object = params)),

               ## logical comparison of whether the "logrank" split rule is used or not
               ## if not, the truncated mean is used
               t_rule = as.integer(x = params@splitRule == 'logrank'),

               ## index (as determined by type of critical value estimator)
               t_sIndex = as.integer(x = ind),

               ## fraction (as determined by type of critical value estimator)
               t_sFraction = as.double(x = frac),

               ## A numeric object. The stratified random split coefficient (as double)
               t_stratifiedSplit = as.double(x = params@stratifiedSplit),

               ## whether or not samplingw/ replacement is used (as an integer)
               ## logical object. TRUE = sample with replacemen
               t_replace = as.integer(params@replace),
               PACKAGE = "IHsurvrf")

# sample size verification (sample size is input)
sampleSize <- .VerifySampleSize(sampleSize = sampleSize,
                                ERT = params@ERT,
                                nDP = nDP)


# ensure that mTry is provided as a vector (input). At this point, there is
# no verification of an appropriate value
if (length(x = mTry) == 1L) {

  ## replicate this to match the number of decision points
  mTry <- rep(x = mTry, times = nDP)

  ## if mTry isn't NULL, and the input lenth if it doesn't match the number of decision points (and it's a vector), output error
} else if (!is.null(x = mTry) && {length(x = mTry) != nDP}) {
  stop("if provided as vector, mTry must be provided for each dp",
       call. = FALSE)
}


# Q-learning algorithm

## initialize an empty lis to store results of the analysis to hold output from each decision point
stageResults <- list()

# final stage analysis

## prints message to the console indicating the current stage being analyzed
## nDP: total number of decision points in the analysis (helps tracks progress of the algorithm)

message("Stage ", nDP)

## calls the .dtrSurvStep() function for the final dedicion point (stage nDP)
## defined in class_DTRSurvStep.R
## use model from last time point
## returns object of class"DTRSurvStep" with the predicted survival curves for each treatment & also the one that's the optimal (based on whatever criteria of interest)

stageResults[[ nDP ]] <- .dtrSurvStep(model = models[[ nDP ]],
                                      data = dt,
                                      priorStep = NULL,
                                      params = params,
                                      txName = txName[nDP],
                                      mTry = mTry[nDP],
                                      sampleSize = sampleSize[nDP])


## testing steps (it works)


stageResults[[3]] <- .dtrSurvStep(model = models[[ 3 ]],
             data = dt,
             priorStep = NULL,
             params = params,
             txName = txName[3],
             mTry = mTry[3],
             sampleSize = sampleSize[3])

## check the optimal ones (this should match the optimal survival functions printed out in stage 2)-- when we then use these to shift
t(.OptimalY(object = stageResults[[3]]@optimal))

stageResults[[2]] <- .dtrSurvStep(model = models[[ 2 ]],
                                  data = dt,
                                  priorStep = stageResults[[3]],
                                  params = params,
                                  txName = txName[2],
                                  mTry = mTry[2],
                                  sampleSize = sampleSize[2])


dt$Y.2

## looking at the structure of the stage results
str(stageResults[[3]]@survRF)

ex_survfunc <- stageResults[[2]]@survRF@forest$survFunc


####################################################################################### OLD testig for .survrf

## ignoring prior step
#
## prepares model frame using the formula (input) and the data (input)
## missing values are not specifically handled (not omitted)
#

### before turning it into a list
x <- stats::model.frame(formula = models, data = dt, na.action = na.pass)
#
# identify individuals with complete data
elig <- stats::complete.cases(x)
#
# extract response and delta from model frame
#
## extract survival response
response <- stats::model.response(data = x)
#
## extract censoring indicator (delta) from the second column of the "response" data
## "L" is used to indicate that 2 is an integer
delta <- response[,2L]
#
## updates the "response" variable to only include the first column of the original "response" data which represents survival times
response <- response[,1L]
#
## if first column of the model frame (x) is the response variable, remove this column
## probablhy to construct predicte response from the predictors, since the response has nothing to do with the prediction itself
if (attr(x = terms(x = models), which = "response") == 1L) {
  x <- x[,-1L,drop = FALSE]
}
#
#
# identify time points <= response
tSurv <- sapply(X = response[elig],
                #
                # results in a logical integer (0 = FALSE)
                FUN = function(s, tp) { as.integer(x = {s < tp}) },
                tp = .TimePoints(object = params))
#
# time point nearest the response without going over
# {nTimes x nElig}
#
## pr: probability mass vector which binds transformed survival times (1, 0) (excluding first row) w values with a row of 1s
## for tSurv,each element is 1 if the survival time < corresponding time point. Otherwise, it's 0
## then subtract the transformed survival times to create a probability mass vector
## this calculates the difference between successive elements in each row of tSurv by translating binary indicators into p.survival until each time point
## there's now mass 1 at time point where each survival time is censored or an event, and 0 for all other time points
#
pr <- {rbind(tSurv[-1L,],1)-tSurv}
#
#
## extract levels of the factor treatment variable for eligible cases
txLevels <- levels(x = factor(x = dt[elig,txName]))
#
#
#
## running code:


result <- .survRF(
  #
  ## selects subset of predictor matrix for eligible cases & ensures result is a matrix
  x = x[elig,,drop=FALSE],
  y = response[elig],
  pr = pr,
  delta = delta[elig],
  params = params,
  mTry = mTry,
  txLevels = txLevels,
  model = models,
  sampleSize = sampleSize)


######### testing .predictSurvTree

newdata = dt[elig,]


## extract levels of all factors in "newdata" to make sure the categorical variables match those used for model training
xLevels <- lapply(X = newdata, FUN = levels)

object = result

## iterate over each variable

for (i in length(x = xLevels)) {

  ## if both the newdata level for ith variable and model level for ith variable are null, skip current iteration

  if (is.null(x = xLevels[[ i ]]) &&
      is.null(x = object@xLevels[[ i ]])) next

  ## if data introduces new factor levels not in model, stop execution and present error message

  if (any(! {xLevels[[ i ]] %in% object@xLevels[[ i ]]})) {
    stop("new factor levels not present in the training data",
         call. = FALSE)
  }
}

# verify that type of data is the same as the training data
# type means numeric (nCat = 0), ordered factor (nCat = 1), or
# factor (nCat = length(levels(x)))

## determines number of categories for each variable in newdata

nCat <- sapply(X = xLevels, FUN = length)

## if ncat is ordered factors, adjust this value to 1

nCat <- ifelse(test = sapply(X = newdata, FUN = is.ordered),
               yes = 1L,
               no = nCat)

## if the datatypes in model don't match the data types in nCat,
# object@nCat is from the input survRF object

if (any(unlist(x = object@nCat) != unlist(x = nCat))) {

  ## stop running and output warning message

  stop("type of predictors in newdata do not match the training data",
       call. = FALSE)
}

## retrieves number of trees in the forest from the input survRF object

nTree <- length(x = object@trees)

#pred <- .predictSurvTree(x = newdata,
#                         params = params,
#                         nCat = nCat,
#
#                         ## this is how you know the prediction is for the first tree
#                         ## the trees slot contains a list of all the trees in the forest
#
#
#                         nodes = object@trees[[ 1L ]])


resV <- .PredictAll(
  ## survival RF model stored in "result" is passed as an input
  ## has info containing list of individual trees (trees), aggregated results from forest (forest), variables,
  ## mTry,nCat,levels for each categorical variable (xLevels)
  object = result,

  ## newdata corresponds to eligible cases to be used for predictions
  ## data =  data.frame object containing covariate and treatment histories
  ## this is the same data that we grew the forest on

  newdata = data[elig,],
  params = params,

  ## using the input model, trtmt name, trtmtn levels avaiable at the current stage
  model = mod,
  txName = txName,
  txLevels = txLevels
)



