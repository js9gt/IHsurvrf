


source("R/IH.VerifyData.R")
source("R/IH.VerifyTxName.R")
source("R/IH.VerifyUsePrevTime.R")
source("R/IH.VerifyModels.R")
source("R/class_IH.CriticalValue.R")
source("R/class_IH.TimeInfo.R")
source("R/class_IH.TreeConditions.R")
source("R/IH.VerifySampleSize.R")
source("R/class_IH.Parameters.R")
source("R/class_IH.DTRSurv.R")


library(survival)
library(IHsurvrf)

dyn.load("src/IHsurvrf.so")


dtrSurv <- function(data,
                    txName,
                    models,
                    ...,
                    usePrevTime = TRUE,
                    timePoints = "quad",
                    nTimes = 100L,
                    tau = NULL,
                    criticalValue = "mean",
                    evalTime = NULL,
                    splitRule = NULL,
                    ERT = TRUE,
                    uniformSplit = NULL,
                    sampleSize = NULL,
                    replace = NULL,

                    ## fed into fortran via setUpBasics as "rs" (global param)
                    randomSplit = 0.2,
                    tieMethod = "random",
                    minEvent = 3L,
                    nodeSize = 6L,
                    nTree = 10L,
                    mTry = NULL,
                    pooled = FALSE,
                    stratifiedSplit = NULL,
                    stageLabel = ".") {
  ## data verification

  # ensure that 'data' is provided as a data.frame or a matrix and does not
  # contain NaN values. If 'data' is appropriate, method returns a data.frame
  # object

  ## used in VerifyData.R script

  data <- .VerifyData(data = data)


  # total number of individuals in dataset
  nSamples <- nrow(x = data)

  # ensure that 'txName' is provided as a character or character vector and
  # that the provided names are present in 'data'. This input defines the
  # number of decision points for the analysis. If 'txName' is appropriate,
  # the object returned is the original input without modification.

  ## defined in VerifyTxName.R Script

  txName <- .VerifyTxName(txName = txName, data = data)

  ## The treatment variable name for
  #   each decision point. Each element corresponds to the respective decision point
  # element 1 = 1st decision; element 2 = 2nd decision, etc..

  # number of decision points in the analysis
  nDP <- length(x = txName)

  # ensures that the usePrevTime input is of appropriate type (a logical)

  ## defined in VerifyUsePrevTime.R script

  usePrevTime <- .VerifyUsePrevTimes(usePrevTimes = usePrevTime)

  # ensure that 'models' is provided as a formula or a list of formula and
  # that the provided models can be generated by the data. If the input is
  # appropriate, the object returned is list containing
  #   "models" - the original input.
  #   "response" - matrix of the survival response variables

  ## used in script VerifyModels.R
  ## this can be input as a list ofmodels, or a single formula (in which we probably assume common formula across all stages)

  models <- .VerifyModels(
    models = models,
    nDP = nDP,
    data = data,
    txName = txName,
    stageLabel = stageLabel,
    usePrevTime = usePrevTime
  )

  ## extracts the "response variable": matrix of survival response variables
  ## these were output from the .VerifyModels object
  response <- models$response

  ## extracts the "delta" variable
  del <- models$delta

  ## only including the models themselves & discarding "response" and "delta" components
  models <- models$models

  ## if models isn't a list already, wraps "models" in a list
  ## ensures uniform handling of "models" whether there is one or multiple decision points in an analysis

  # convert to list for single decision analyses for convenience
  if (!is.list(x = models))
    models <- list(models)


  params <- .parameters(
    timePoints = timePoints,
    tau = tau,
    nTimes = nTimes,

    ## response is created (not input)
    response = response,
    nTree = nTree,
    ERT = ERT,
    uniformSplit = uniformSplit,
    randomSplit = randomSplit,
    splitRule = splitRule,
    replace = replace,
    nodeSize = nodeSize,
    minEvent = minEvent,
    tieMethod = tieMethod,
    criticalValue = criticalValue,
    survivalTime = evalTime,

    ## nSamples is created (not input)
    nSamples = nSamples,
    pooled = pooled,
    stratifiedSplit = stratifiedSplit
  )


  # store basic information on fortran side

  ## .CriticalValueCriterion:
  ## if the object type is "mean", then return "surv.mean" if object type is "prob", return the "surv.prob"


  # retrieve index and fraction if survival type value estimator
  # set as 0's if mean estimator

  crit <- .CriticalValueCriterion(params)
  if (crit == "mean") {
    ## set index to 0 (integer)
    ind = 0L

    ## set fraction to 0.0
    frac = 0.0

    ## meaning, for mean-based criteria, specific index and fraction aren't applicable or needed

  } else if (crit == "surv.mean" || crit == "surv.prob") {
    ## retrieve the "Index" and the"sFraction" from the params object
    ## these are output depending on the input "survivalTime" parameter
    ind = params@sIndex
    frac = params@sFraction
  }

  # set basic parameter values in Fortran
  ## call a Fortran subroutine named "setUpBasics"
  ## in dtrSurv.f90 code
  ## basically just outputs the input info

  res = .Fortran(
    "setUpBasics",

    ## retrieve the number of timepoints
    t_nt = as.integer(x = .NTimes(object = params)),

    ## retrieve the difference in timepoints
    t_dt = as.double(x = .TimeDiff(object = params)),

    ## retrieves the "randomSplit" (input) parameter as a double
    ## this is then fed into fortran as the probability of random split (rs)
    t_rs = as.double(x = params@randomSplit),

    ## retrieves logical of whether extremeley randomized trees *ERT* are used (as integer)
    t_ERT = as.integer(x = params@ERT),

    ## retrieves logical of whether uniform splits are used (as integer)
    t_uniformSplit = as.integer(x = params@uniformSplit),

    ## min number of samples required at a tree node to consider a split (as integer)
    ## defined in class_IH.TreeConditions
    t_nodeSize = as.integer(x = .NodeSize(object = params)),

    ## min number of events present in node (as integer)
    ## defined in class_TreeConditions.R
    ## return the minEvent slot (integer): minimum number of events allowed in a node

    t_minEvent = as.integer(x = .MinEvent(object = params)),

    ## logical comparison of whether the "logrank" split rule is used or not
    ## if not, the truncated mean is used
    t_rule = as.integer(x = params@splitRule == 'logrank'),

    ## index (as determined by type of critical value estimator)
    t_sIndex = as.integer(x = ind),

    ## fraction (as determined by type of critical value estimator)
    t_sFraction = as.double(x = frac),

    ## A numeric object. The stratified random split coefficient (as double)
    t_stratifiedSplit = as.double(x = params@stratifiedSplit),

    ## whether or not samplingw/ replacement is used (as an integer)
    ## logical object. TRUE = sample with replacemen
    t_replace = as.integer(params@replace),
    PACKAGE = "IHsurvrf"
  )

  ## sample size verification

  # ensure that if given, sampleSize is 0 < sampleSize <= 1 and that
  # a value is provided for each decision point. If only 1 value is given,
  # it is assumed to be used for all decision points

  ## used in VerifySampleSize.R Script
  ## 'sampleSize' is numeric, numeric vector, or NULL. If NULL, set
  ##   to a default value based on ERT selection.

  ## if input is NULL & ERT is used, defaults sampleSize to 1.0 (using all data)
  ## if input is NULL & ERT is not used, uses a default fraction of 0.632 of the data used

  sampleSize <- .VerifySampleSize(sampleSize = sampleSize,
                                  ERT = params@ERT,
                                  nDP = nDP)

  ## checks if mTry is a scalar (has length 1). If so,

  # ensure that mTry is provided as a vector. At this point, there is
  # no verification of an appropriate value
  if (length(x = mTry) == 1L) {
    ## replicate this to match the number of decision points
    mTry <- rep(x = mTry, times = nDP)

    ## if mTry isn't NULL, and the input lenth if it doesn't match the number of decision points (and it's a vector), output error
  } else if (!is.null(x = mTry) && {
    length(x = mTry) != nDP
  }) {
    stop("if provided as vector, mTry must be provided for each dp",
         call. = FALSE)
  }

  # Q-learning algorithm

  ## initialize an empty lis to store results of the analysis to hold output from each decision point
  stageResults <- list()

  # final stage analysis

  ## prints message to the console indicating the current stage being analyzed
  ## nDP: total number of decision points in the analysis (helps tracks progress of the algorithm)

  message("Stage ", nDP)

  ## calls the .dtrSurvStep() function for the final dedicion point (stage nDP)
  ## defined in class_DTRSurvStep.R
  ## use model from last time point
  ## returns object of class"DTRSurvStep" with the predicted survival curves for each treatment & also the one that's the optimal (based on whatever criteria of interest)

  stageResults[[nDP]] <- .dtrSurvStep(
    model = models[[nDP]],
    data = data,
    priorStep = NULL,
    params = params,
    txName = txName[nDP],
    mTry = mTry[nDP],
    sampleSize = sampleSize[nDP]
  )


  ## preparing for backwards recursion by going a step backwards stage-wise

  q <- nDP - 1L


  # backward recursion

  ## looking through the rest of the stages , stopping after reaching stage 1

  while (q >= 1L) {
    ## display the current stage number to the user to track progress

    message("Stage ", q)

    ## calls the .dtrSurvStep() function for the current stage
    ## defined in class_DTRSurvStep.R
    ## use model at q-th stage

    stageResults[[q]] <- .dtrSurvStep(
      model = models[[q]],
      data = data,
      ## use the results from the next stage
      ## has survival function estimated from next stage, S_(t+1)
      ## extracts survival times corresponding to eligible cases at current time point, S_t
      ## then shifts survival function down in time: s_(t+1) - S_t
      ## transforms this into probability mass format
      ## then generate a forest with this using .survRF using "survTree" fortran
      ## BUT... this loops through trees which we don't have an input for the number of trees we want
      ## BUT I think this is in the "nTree" input as a global variable??
      priorStep = stageResults[[q + 1L]],
      params = params,
      txName = txName[q],
      mTry = mTry[q],
      sampleSize = sampleSize[q]
    )

    ## decrease the counter

    q <- q - 1L


    ############# mean value results
    ## mean of maximum expected survival times across treatment levels & mean of maximum expeced survival probabilities
    ## these are returned (not calculated) based on the maximum value for whatever the best treatment is
    ## ex) mean 1 (for trt1), mean2 (for trt2); we identify which the maximum is
  }

  # value obtained from the first stage analysis

  ## after backwards recursion is complete, calculate the estimated value from the first stage
  ## calculates mean values of expected survival times and survival probabilities
  ## this is calculated across all PTS, so, once all pts have received their estimated optimal treatment --> what's the mean of all their survival times
  ## .meanValue() function defined in class_DTRSurvStep.R

  valueTrain <- .meanValue(object = stageResults[[1L]])

  ## display the estimated value calculated in the first stage, and iterates through each element and prints names and values

  message("Estimated Value:", appendLF = FALSE)
  for (i in 1L:length(valueTrain)) {
    message(" ", names(valueTrain)[i], ": ", valueTrain[[i]], appendLF = FALSE)
  }
  message()


  # store values in call structure for returned object

  ## captures current function call, including function name and all arguments passed to it
  cl <- match.call()

  ## ensures name of called function is set to "dtrSurv"
  cl[[1L]] <- as.name("dtrSurv")

  ## construct an object of class DTRSurv for the output
  ## this is defined in class_IH.DTRSurv.R

  res <- new(
    Class = "DTRSurv",
    "stageResults" = stageResults,
    "value" = valueTrain,
    "call" = cl,
    "params" = params
  )

  return(res)



}


### examples:

### simulate data for 5 stages
dt <- data.frame("Y.1" = sample(1:100,100,TRUE), "Y.2" = sample(1:100,100,TRUE), "Y.3" = sample(1:100,100,TRUE),
                 "Y.4" = sample(1:100,100,TRUE), "Y.5" = sample(1:100,100,TRUE),
                 "D.1" = rbinom(100, 1, 0.9), "D.2" = rbinom(100,1,0.9), "D.3" = rbinom(100,1,0.9),
                 "D.4" = rbinom(100,1,0.9), "D.5" = rbinom(100,1,0.9),
                 "A.1" = rbinom(100, 1, 0.5), "A.2" = rbinom(100,1,0.5), "A.3" = rbinom(100,1,0.5),
                 "A.4" = rbinom(100,1,0.5), "A.5" = rbinom(100,1,0.5),
                 "X.1" = rnorm(100), "X.2" = rnorm(100), "X.3" = rnorm(100), "X.4" = rnorm(100), "X.5" = rnorm(100))

#
#results <- dtrSurv(data = dt,
#       txName = c("A.1", "A.2", "A.3", "A.4", "A.5"),
#       ## using a common formula
#       models = Surv(Y,D)~X,
#       ## pooled analysis (why we include A in formula)
#       pooled = FALSE,
#       usePrevTime = TRUE,
#       stageLabel = ".")
#
#str(results)
#
#results@stageResults[[2]]

### checking that HC code works on my generated data

a <- output2observable(pts)

results <- dtrSurv(data = a,
       txName = paste0("A_", seq(1, 50)),
       ## using a common formula
       models = Surv(T, delta) ~ baseline1 + baseline2 + state + prior.visit.length + cumulative.time + nstages + action_1_count + action_0_count,
       ## pooled analysis (why we include A in formula)
       pooled = FALSE,
       usePrevTime = TRUE,
       stageLabel = "_")


